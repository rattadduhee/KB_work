{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec28ad4b",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04cf9e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "    cancer['data'], cancer['target'], stratify=cancer['target'],  random_state=0\n",
    ")\n",
    "x_tr.shape, x_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac37a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5762f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr',lr), \n",
    "                         ('dt3',dt3), ('dt5',dt5)])\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr',lr), \n",
    "                         ('dt3',dt3), ('dt5',dt5)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c093b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy: 98.12%\n",
      "hard Train Accuracy: 95.10%\n",
      "\n",
      "soft Train Accuracy: 99.53%\n",
      "soft Train Accuracy: 95.80%\n",
      "\n",
      "knn1 Train Accuracy: 94.60%\n",
      "knn1 Train Accuracy: 91.61%\n",
      "\n",
      "knn2 Train Accuracy: 95.77%\n",
      "knn2 Train Accuracy: 91.61%\n",
      "\n",
      "lr Train Accuracy: 96.71%\n",
      "lr Train Accuracy: 93.71%\n",
      "\n",
      "dt3 Train Accuracy: 97.65%\n",
      "dt3 Train Accuracy: 91.61%\n",
      "\n",
      "dt5 Train Accuracy: 100.00%\n",
      "dt5 Train Accuracy: 92.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_tr, y_tr) * 100\n",
    "    test_score = model.score(x_te, y_te) * 100\n",
    "    print(f'{name} Train Accuracy: {train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy: {test_score:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5bf4e",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc4d6174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.951048951048951)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=5).fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca0b46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9647887323943662, 0.9300699300699301)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=2).fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45b5ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9366197183098591, 0.9230769230769231)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=1).fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9cd2cd",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a802b162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.958041958041958)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(x_tr, y_tr)\n",
    "model.score(x_tr, y_tr), model.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfd5cb",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba369dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()),\n",
    "              ('gb', GradientBoostingClassifier())]\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                          final_estimator=LogisticRegression())\n",
    "model.fit(x_tr, y_tr).score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f655ddf",
   "metadata": {},
   "source": [
    "## 손글씨 데이터 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e3af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy: 99.68%\n",
      "hard Test Accuracy: 98.52%\n",
      "\n",
      "soft Train Accuracy: 99.84%\n",
      "soft Test Accuracy: 98.52%\n",
      "\n",
      "knn Train Accuracy: 99.20%\n",
      "knn Test Accuracy: 98.52%\n",
      "\n",
      "lr Train Accuracy: 100.00%\n",
      "lr Test Accuracy: 96.67%\n",
      "\n",
      "dt Train Accuracy: 74.30%\n",
      "dt Test Accuracy: 72.04%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digit = load_digits()\n",
    "y = digit['target']\n",
    "X = digit['data']\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "    X, y, random_state=0, stratify=y, test_size=0.3\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr',lr), \n",
    "                         ('dt3',dt3), ('dt5',dt5)])\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr',lr), \n",
    "                         ('dt3',dt3), ('dt5',dt5)], voting = 'soft')\n",
    "\n",
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "\n",
    "for idx, model in enumerate([hard, soft, knn, lr, dt]):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_tr, y_tr) * 100\n",
    "    test_score = model.score(x_te, y_te) * 100\n",
    "    print(f'{name} Train Accuracy: {train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy: {test_score:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b73dbd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "best_model = {}\n",
    "\n",
    "# 데이터 분할\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(digits['data'],\n",
    "                                                    digits['target'],\n",
    "                                                    stratify=digits['target'],\n",
    "                                                    random_state=0)\n",
    "\n",
    "# 모델 설정\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr), ('dt3', dt3), ('dt5', dt5)])\n",
    "\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr), ('dt3', dt3), ('dt5', dt5)], voting='soft')\n",
    "\n",
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_tr, y_tr)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_tr, y_tr) * 100\n",
    "    test_score = model.score(x_te, y_te) * 100\n",
    "    best_model[name] = [test_score]\n",
    "    \n",
    "# bagging\n",
    "for i in range(1, 6):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(max_depth=i).fit(x_tr, y_tr)\n",
    "    best_model[f'bagging, max_depth={i}'] = [model.score(x_te, y_te)]\n",
    "    \n",
    "# boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(x_tr, y_tr)\n",
    "best_model['boosting'] = [model.score(x_te, y_te)]\n",
    "\n",
    "# stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()),\n",
    "             ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                          final_estimator=LogisticRegression())\n",
    "\n",
    "best_model['stacking'] = [model.fit(x_tr, y_tr).score(x_te, y_te)]\n",
    "\n",
    "# 최댓값 저장 후 출력\n",
    "max_value = max(best_model.values())\n",
    "\n",
    "for key, value in best_model.items():\n",
    "    if value == max_value:\n",
    "        print(f'가장 좋은 모델은 {key}, 성능은 {value:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c849ee39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hard</th>\n",
       "      <td>98.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft</th>\n",
       "      <td>97.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn1</th>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn2</th>\n",
       "      <td>98.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>96.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt3</th>\n",
       "      <td>46.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt5</th>\n",
       "      <td>67.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging, max_depth=1</th>\n",
       "      <td>0.804444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging, max_depth=2</th>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging, max_depth=3</th>\n",
       "      <td>0.875556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging, max_depth=4</th>\n",
       "      <td>0.924444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging, max_depth=5</th>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting</th>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacking</th>\n",
       "      <td>0.975556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0\n",
       "hard                  98.222222\n",
       "soft                  97.777778\n",
       "knn1                  98.000000\n",
       "knn2                  98.666667\n",
       "lr                    96.444444\n",
       "dt3                   46.888889\n",
       "dt5                   67.555556\n",
       "bagging, max_depth=1   0.804444\n",
       "bagging, max_depth=2   0.820000\n",
       "bagging, max_depth=3   0.875556\n",
       "bagging, max_depth=4   0.924444\n",
       "bagging, max_depth=5   0.944444\n",
       "boosting               0.966667\n",
       "stacking               0.975556"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "best_model_df = pd.DataFrame(best_model).T\n",
    "best_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cfe9d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knn2'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_df.sort_values(0, ascending=False).reset_index()\n",
    "best_model_df.sort_values(0, ascending=False).reset_index().loc[0,\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188f24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
